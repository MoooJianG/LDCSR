model:
  target: models.first_stage_kl_atom.AutoencoderKL
  base_learning_rate: 4.5e-06
  monitor: val/rec_loss
  monitor_mode: min
  params:
    ckpt_path: logs/first_stage_kl_v6/2024-06-03T00-10-18/checkpoints/last.ckpt
    embed_dim: 4
    lossconfig:
      target: losses.contperceptual.LPIPSWithDiscriminator
      params:
        disc_start: 50001
        kl_weight: 1.0e-06
        disc_weight: 0.5
    encoder_config:
      target: modules.e2sr.s1_v6.GAPEncoder
      params:
        in_channels: 6
        ch: 64
        ch_mult: [1, 2, 2, 4]
        num_res_blocks: 2
        attn_resolutions: []
        z_channels: 4
        double_z: true
    decoder_config:
      target: modules.e2sr.s1_v6.GAPDecoder
      params:
        ch: 64
        out_ch: 3
        ch_mult: [1, 1, 1, 1]
        num_res_blocks: 2
        attn_resolutions: []
        z_channels: 4
        in_channels: 3
        num_sr_modules: [12, 12, 12, 12]
data:
  target: data.datamodule.DataModuleFromConfig
  params:
    batch_size: 4
    num_workers: 8
    wrap: false
    train:
      target: data.downsampled_dataset.MultiScaleDownsampledDataset
      params:
        datapath: load/WorldStrat_png_v2/train/HR
        min_scale: 4
        max_scale: 4
        is_train: true
        lr_img_sz: 48
        cache: memory
        data_length: 4000
        batch_size: 4
        # split_file_path: data/AID_split.pkl
        # split: train
    validation:
      target: data.downsampled_dataset.DownsampledDataset
      params:
        datapath: load/WorldStrat_png_v2/test
        scale: 4
        is_train: false
        first_k: 2
        cache: memory
        # split_file_path: data/AID_split.pkl
        # split: val

#################################
##  Configs for the Lightning  ##
#################################
lightning:
  trainer:
    max_epochs: 1000
    reload_dataloaders_every_n_epochs: 1