model:
  target: models.first_stage_kl_atom.AutoencoderKL
  base_learning_rate: 4.5e-06
  monitor: val/rec_loss
  monitor_mode: min
  params:
    embed_dim: 4
    lossconfig:
      target: losses.contperceptual.LPIPSWithDiscriminator
      params:
        disc_start: 50001
        kl_weight: 1.0e-06
        disc_weight: 0.5
    encoder_config:
      target: modules.e2sr.s1_v6_fixed_scale.GAPEncoder
      params:
        in_channels: 6
        ch: 64
        ch_mult: [1, 2, 2, 4]
        num_res_blocks: 2
        attn_resolutions: []
        z_channels: 4
        double_z: true
    decoder_config:
      target: modules.e2sr.s1_v6_fixed_scale.GAPDecoder
      params:
        ch: 64
        out_ch: 3
        ch_mult: [1, 1, 1, 1]
        num_res_blocks: 2
        attn_resolutions: []
        z_channels: 4
        scale: 4
        in_channels: 3
        num_sr_modules: [12, 12, 12, 12]
data:
  target: data.datamodule.DataModuleFromConfig
  params:
    batch_size: 8
    num_workers: 8
    wrap: false
    train:
      target: data.downsampled_dataset.DownsampledDataset
      params:
        datapath: load/AID_split/train/HR
        scale: 4
        is_train: true
        lr_img_sz: 64
        cache: memory
        data_length: 4000
    validation:
      target: data.downsampled_dataset.DownsampledDataset
      params:
        datapath: load/AID_split/val/HR
        scale: 4
        is_train: false
        first_k: 2
        cache: memory

#################################
##  Configs for the Lightning  ##
#################################
lightning:
  trainer:
    max_epochs: 1000
    reload_dataloaders_every_n_epochs: 1